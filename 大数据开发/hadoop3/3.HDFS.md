# HDFS

# ä¸€.æ¦‚è¿°

Hadoop Distributed File Systemï¼Œå®ƒæ˜¯ä¸€ä¸ª**æ–‡ä»¶ç³»ç»Ÿ**ï¼Œç”¨äºå­˜å‚¨æ–‡ä»¶ï¼Œé€šè¿‡ç›®å½•æ ‘æ¥å®šä½æ–‡ä»¶ï¼›å®ƒæ˜¯**åˆ†å¸ƒå¼**çš„ï¼Œç”±å¾ˆå¤šæœåŠ¡å™¨è”åˆèµ·æ¥å®ç°å…¶åŠŸèƒ½ï¼Œé›†ç¾¤ä¸­çš„æœåŠ¡å™¨æœ‰å„è‡ªçš„è§’è‰²



## 1.1 ä½¿ç”¨åœºæ™¯

é€‚åˆä¸€æ¬¡å†™å…¥ï¼Œå¤šæ¬¡è¯»å‡ºçš„åœºæ™¯ã€‚ä¸€ä¸ªæ–‡ä»¶ç»è¿‡åˆ›å»ºã€å†™å…¥å’Œå…³é—­ä¹‹åå°±ä¸éœ€è¦æ”¹å˜



## 1.2 HDFSçš„ä¼˜ç¼ºç‚¹

> HDFSä¼˜ç‚¹:

- `é«˜å®¹é”™æ€§`ï¼š

  - æ•°æ®è‡ªåŠ¨ä¿å­˜å¤šä¸ªå‰¯æœ¬ã€‚å®ƒé€šè¿‡å¢åŠ å‰¯æœ¬çš„å½¢å¼

    ![image-20230926105736294](img.assets\image-20230926105736294.png)

  - æé«˜å®¹é”™æ€§ã€‚æŸä¸€ä¸ªå‰¯æœ¬ä¸¢å¤±ä»¥åï¼Œå®ƒå¯ä»¥è‡ªåŠ¨æ¢å¤

![image-20230926105751980](img.assets\image-20230926105751980.png)

- `é€‚åˆå¤„ç†å¤§æ•°æ®`ï¼šæ•°æ®è§„æ¨¡å¤§ï¼Œèƒ½å¤Ÿå¤„ç†æ•°æ®è§„æ¨¡è¾¾åˆ°GBã€TBã€ç”šè‡³PBçº§åˆ«çš„æ•°æ®ï¼›æ–‡ä»¶è§„æ¨¡å¤§ï¼Œèƒ½å¤Ÿå¤„ç†ç™¾ä¸‡è§„æ¨¡ä»¥ä¸Šçš„æ–‡ä»¶æ•°é‡ï¼Œæ•°é‡ç›¸å½“ä¹‹å¤§ã€‚

- `å¯æ„å»ºåœ¨å»‰ä»·æœºå™¨ä¸Š`ï¼Œé€šè¿‡å¤šå‰¯æœ¬æœºåˆ¶ï¼Œæé«˜å¯é æ€§

> HDFSçš„ç¼ºç‚¹

- ä¸é€‚åˆä½å»¶æ—¶æ•°æ®è®¿é—®ï¼Œæ¯”å¦‚æ¯«ç§’çº§çš„å­˜å‚¨æ•°æ®ï¼Œæ˜¯åšä¸åˆ°çš„ã€‚
- æ— æ³•é«˜æ•ˆçš„å¯¹å¤§é‡å°æ–‡ä»¶è¿›è¡Œå­˜å‚¨ã€‚
  - å­˜å‚¨å¤§é‡å°æ–‡ä»¶çš„è¯ï¼Œå®ƒä¼šå ç”¨NameNodeå¤§é‡çš„å†…å­˜æ¥å­˜å‚¨æ–‡ä»¶ç›®å½•å’Œå—ä¿¡æ¯ï¼Œå› ä¸ºNameNodeçš„å†…å­˜æ€»æ˜¯æœ‰é™çš„ï¼›
  - å°æ–‡ä»¶å­˜å‚¨çš„å¯»å€æ—¶é—´ä¼šè¶…è¿‡è¯»å–æ—¶é—´ï¼Œå®ƒè¿åäº†HDFSçš„è®¾è®¡ç›®æ ‡ã€‚
- ä¸æ”¯æŒå¹¶å‘å†™å…¥ã€æ–‡ä»¶éšæœºä¿®æ”¹ã€‚**ä¸€ä¸ªæ–‡ä»¶åªèƒ½æœ‰ä¸€ä¸ªå†™ï¼Œä¸å…è®¸å¤šä¸ªçº¿ç¨‹åŒæ—¶å†™ï¼›ä»…æ”¯æŒæ•°æ®append(è¿½åŠ )ï¼Œä¸æ”¯æŒæ–‡ä»¶çš„éšæœºä¿®æ”¹**





# äºŒ.HDFSçš„ç»„æˆ

[æŸ¥çœ‹æ‰€æœ‰ç‰ˆæœ¬çš„Hadoopæ–‡æ¡£](https://hadoop.apache.org/docs/)

> 3.1.3ç‰ˆæœ¬HDFSçš„ç»„æˆå›¾

![image-20230926110359108](img.assets\image-20230926110359108.png)

> `NameNode`(nn):Masterï¼Œå®ƒæ˜¯ä¸€ä¸ªä¸»ç®¡ã€ç®¡ç†è€…

- ç®¡ç†HDFSçš„åç§°ç©ºé—´ã€‚

- é…ç½®å‰¯æœ¬ç­–ç•¥ã€‚

- ç®¡ç†æ•°æ®å—ï¼ˆBlockï¼‰æ˜ å°„ä¿¡æ¯ã€‚

- å¤„ç†å®¢æˆ·ç«¯è¯»å†™è¯·æ±‚ã€‚

>`DataNode`ï¼šå°±æ˜¯Slaveã€‚NameNodeä¸‹è¾¾å‘½ä»¤ï¼ŒDataNodeæ‰§è¡Œå®é™…çš„æ“ä½œã€‚

- å­˜å‚¨å®é™…çš„æ•°æ®å—ã€‚

- æ‰§è¡Œæ•°æ®å—çš„è¯»/å†™æ“ä½œã€‚

> `Client`ï¼šå®¢æˆ·ç«¯

- æ–‡ä»¶åˆ‡åˆ†ã€‚æ–‡ä»¶ä¸Šä¼ HDFSçš„æ—¶å€™ï¼ŒClientå°†æ–‡ä»¶åˆ‡åˆ†æˆä¸€ä¸ªä¸€ä¸ªçš„Blockï¼Œç„¶åè¿›è¡Œä¸Šä¼ ã€‚
- ä¸NameNodeäº¤äº’ï¼Œè·å–æ–‡ä»¶çš„ä½ç½®ä¿¡æ¯ã€‚
- ä¸DataNodeäº¤äº’ï¼Œè¯»å–æˆ–è€…å†™å…¥æ•°æ®ã€‚
- Clientæä¾›ä¸€äº›å‘½ä»¤æ¥ç®¡ç†HDFSï¼Œæ¯”å¦‚NameNodeæ ¼å¼åŒ–ã€‚
- Clientå¯ä»¥é€šè¿‡ä¸€äº›å‘½ä»¤æ¥è®¿é—®HDFSï¼Œæ¯”å¦‚å¯¹HDFSå¢åˆ æŸ¥æ”¹æ“ä½œã€‚

> `Secondary NameNode`(2nn)ï¼šå¹¶éNameNodeçš„çƒ­å¤‡ã€‚å½“NameNodeæŒ‚æ‰çš„æ—¶å€™ï¼Œå®ƒå¹¶ä¸èƒ½é©¬ä¸Šæ›¿æ¢NameNodeå¹¶æä¾›æœåŠ¡ã€‚

- è¾…åŠ©NameNodeï¼Œåˆ†æ‹…å…¶å·¥ä½œé‡ï¼Œæ¯”å¦‚å®šæœŸåˆå¹¶Fsimageå’ŒEditsï¼Œå¹¶æ¨é€ç»™NameNode ã€‚

- åœ¨ç´§æ€¥æƒ…å†µä¸‹ï¼Œå¯è¾…åŠ©æ¢å¤NameNodeã€‚



# ä¸‰.HDFSæ–‡ä»¶å—å¤§å° â­

HDFSä¸­çš„æ–‡ä»¶åœ¨ç‰©ç†ä¸Šæ˜¯åˆ†å—å­˜å‚¨ï¼ˆBlockï¼‰ï¼Œå—çš„å¤§å°å¯ä»¥é€šè¿‡é…ç½®å‚æ•°(`dfs.blocksize`)æ¥è§„å®šï¼Œé»˜è®¤å¤§å°åœ¨Hadoop2.x/3.xç‰ˆæœ¬ä¸­æ˜¯`128M`ï¼Œ1.xç‰ˆæœ¬ä¸­æ˜¯64M,**HDFSå—çš„å¤§å°è®¾ç½®ä¸»è¦å–å†³äº`ç£ç›˜ä¼ è¾“é€Ÿç‡`ï¼ˆç”±è¯»å†™é€Ÿåº¦å†³å®šï¼‰**

> åœ¨hdfs-default.xmlæ–‡ä»¶ä¸­çš„dfs.blocksize

```xml
<property>
  <name>dfs.blocksize</name>
  <value>134217728</value>
  <description>
      The default block size for new files, in bytes.
      You can use the following suffix (case insensitive):
      k(kilo), m(mega), g(giga), t(tera), p(peta), e(exa) to specify the size (such as 128k, 512m, 1g, etc.),
      Or provide complete size in bytes (such as 134217728 for 128 MB).
  </description>
</property>
```



![image-20230926120747188](img.assets\image-20230926120747188.png)

> ä¸ºä»€ä¹ˆå—çš„å¤§å°ä¸èƒ½è®¾ç½®å¤ªå°ï¼Œä¹Ÿä¸èƒ½è®¾ç½®å¤ªå¤§ï¼Ÿ

- HDFSçš„å—è®¾ç½®å¤ªå°ï¼Œä¼šå¢åŠ å¯»å€æ—¶é—´ï¼Œç¨‹åºä¸€ç›´åœ¨æ‰¾å—çš„å¼€å§‹ä½ç½®ã€‚

- å¦‚æœå—è®¾ç½®çš„å¤ªå¤§ï¼Œä¸åˆ©äºå¹¶å‘è¿ç®—ï¼Œä»ç£ç›˜ä¼ è¾“æ•°æ®çš„æ—¶é—´ä¼šæ˜æ˜¾å¤§äºå®šä½è¿™ä¸ªå—å¼€å§‹ä½ç½®æ‰€éœ€çš„æ—¶é—´ã€‚å¯¼è‡´ç¨‹åºåœ¨å¤„ç†è¿™å—æ•°æ®æ—¶ï¼Œä¼šéå¸¸æ…¢ã€‚



# å››.HDFSçš„shellæ“ä½œâ­

åŸºæœ¬è¯­æ³•ï¼š

> `hadoop fs` [é€‰é¡¹] [å¯¹è±¡] æˆ– `hdfs dfs` [é€‰é¡¹] [å¯¹è±¡]

## 4.1 æŸ¥çœ‹å‘½å

`hadoop fs / hdfs dfs`ï¼šæŸ¥çœ‹å‘½ä»¤å¤§å…¨ï¼Œ`hadoop fs -help å‘½ä»¤` å¯¹åº”å‘½ä»¤çš„ç”¨æ³•



## 4.2 åˆ›å»ºæ–‡ä»¶å¤¹

```shell
hadoop fs -mkdir /ç›®å½•åç§°
```



## 4.3 ä¸Šä¼ 

**`hadoop fs -moveFromLocal è¦ä¼ çš„æ–‡ä»¶ è¦ä¼ å…¥çš„ç›®å½•ä¸‹/æ–‡ä»¶å`** ä»æœ¬åœ°å‰ªåˆ‡æ–‡ä»¶åˆ°HDFSè·¯å¾„å»

**`hadoop fs -put/copyFromLocal è¦ä¼ çš„æ–‡ä»¶ è¦ä¼ å…¥çš„ç›®å½•ä¸‹/æ–‡ä»¶å `**ä»æœ¬åœ°å¤åˆ¶æ–‡ä»¶åˆ°HDFSè·¯å¾„å»

**`hadoop fs -appendToFile è¦è¿½åŠ çš„æ–‡ä»¶ è¦è¿½åŠ è¿›çš„æ–‡ä»¶ä¸­/æ–‡ä»¶å`** è¿½åŠ ä¸€ä¸ªæ–‡ä»¶åˆ°å·²ç»å­˜åœ¨çš„æ–‡ä»¶æœ«å°¾

```shell
# å…ˆåœ¨æœ¬åœ°åˆ›å»ºtxtæ–‡ä»¶
touch shuguo.txt
echo "hello,shuguo" >> shuguo.txt

# ä¸Šä¼ è‡³/sanguoç›®å½•ä¸‹ï¼ˆç›´æ¥ç§»åŠ¨è¿‡å»ï¼‰
hadoop fs -moveFromLocal shuguo.txt /sanguo
# å¤åˆ¶è¿‡å»
hadoop fs -put weiguo.txt /sanguo/caowei.txt
# è¿½åŠ åˆ°æœ«å°¾
hadoop fs -appendToFile liubei.txt /sanguo/shuguo.txt
```



## 4.4 ä¸‹è½½

**`hadoop fs -copyToLocal/get`** è¦ä¸‹è½½çš„æ–‡ä»¶ è¦ä¸‹è½½çš„ç›®å½•ä¸‹/æ–‡ä»¶å

```shell
# å°†shuguo.txtæ‹·è´å›æœ¬åœ°ï¼Œå¹¶æ›´åä¸ºshu.txt
hadoop fs -get /sanguo/shuguo.txt shu.txt
```



## 4.5 HDFSçš„ç›´æ¥æ“ä½œ

| **é€‰é¡¹** |               åŠŸèƒ½                |                          ä¾‹å­                           |
| :------: | :-------------------------------: | :-----------------------------------------------------: |
|   -ls    |           æ˜¾ç¤ºç›®å½•ä¿¡æ¯            |                    `hadoop fs -ls /`                    |
|   -cat   |           æ˜¾ç¤ºæ–‡ä»¶å†…å®¹            |           `hadoop fs -cat /sanguo/shuguo.txt`           |
|  -chmod  |            å˜æ›´æ–‡ä»¶rwx            |        `hadoop fs -chmod 777 /sanguo/shuguo.txt`        |
|  -chgrp  |              æ›´æ”¹ç»„               |      `hadoop fs -charp ygy:ygy /sanguo/shuguo.txt`      |
|  -chown  |            æ›´æ”¹æ‰€æœ‰è€…             |     `hadoop fs -charp root:ygy /sanguo/shuguo.txt`      |
|  -mkdir  |             åˆ›å»ºè·¯å¾„              |               `hadoop fs -mkdir /jinguo`                |
|   -cp    |  åœ¨HDFSçš„æŸè·¯å¾„æ‹·è´åˆ°å¦ä¸€ä¸ªè·¯å¾„   |       `hadoop fs -cp /shuguo/shuguo.txt /jinguo`        |
|   -mv    |       åœ¨HDFSç›®å½•ä¸­ç§»åŠ¨æ–‡ä»¶        |       `hadoop fs -mv /sanguo/weiguo.txt /jinguo`        |
|  -tail   | æ˜¾ç¤ºæ–‡ä»¶æœ«å°¾1kbçš„æ•°æ®ï¼ˆæœ€åæœ€æ–°ï¼‰ |          `hadoop fs -tail /jinguo/shuguo.txt`           |
|   -rm    |         åˆ é™¤æ–‡ä»¶æˆ–æ–‡ä»¶å¤¹          |             `hadoop -rm /sanguo/shuguo.txt`             |
|  -rm -r  |  é€’å½’åˆ é™¤ç›®å½•ä»¥åŠåŒ…å«å…¶ä¸­çš„æ–‡ä»¶   |               `hadoop fs -rm -r /sanguo`                |
|   -du    |        ç»Ÿè®¡æ–‡ä»¶å¤¹å¤§å°ä¿¡æ¯         | `hadoop fs -du -s -h /jinguo`ï¼Œ-såªæ˜¾ç¤ºæ€»å’Œï¼Œ-hé˜…è¯»å‹å¥½ |
| -setrep  |     è®¾ç½®HDFSä¸­æ–‡ä»¶çš„å‰¯æœ¬æ•°é‡      |        `hadoop fs -setrep 10 /jinguo/shuguo.txt`        |

```shell
# -duæŸ¥çœ‹æ–‡ä»¶å¤¹å¤§å°ä¿¡æ¯
hadoop fs -du -sh /jinguo
# æŠ¥é”™ğŸ˜‡
-du: Illegal option -sh
# -shä¸åƒshellä¸­å¯ä»¥åˆèµ·æ¥å†™,ä½†åŠŸèƒ½ä¸€è‡´
hadoop fs -du -s -h /jinguo

# è¾“å‡º
  182           546       /sanguo
#æ–‡ä»¶å¤§å°  æ–‡ä»¶å¤§å°*å‰¯æœ¬æ•°  æŸ¥çœ‹çš„ç›®å½•
```

>è¿™é‡Œè®¾ç½®çš„å‰¯æœ¬æ•°åªæ˜¯è®°å½•åœ¨ NameNode çš„å…ƒæ•°æ®ä¸­ï¼Œæ˜¯å¦çœŸçš„ä¼šæœ‰è¿™ä¹ˆå¤šå‰¯æœ¬ï¼Œè¿˜å¾—çœ‹ DataNode çš„æ•°é‡ã€‚å› ä¸ºç›®å‰åªæœ‰ 3 å°è®¾å¤‡ï¼Œæœ€å¤šä¹Ÿå°± 3 ä¸ªå‰¯æœ¬ï¼Œåªæœ‰èŠ‚ç‚¹æ•°çš„å¢åŠ åˆ°10å°æ—¶ï¼Œå‰¯æœ¬æ•°æ‰èƒ½è¾¾åˆ° 10



# äº”.HDFSçš„APIæ“ä½œ

## 5.1 windosæœ¬åœ°å®‰è£…é…ç½®hadoop

å°†`bin`ç›®å½•è§£å‹è‡³ä¸€ä¸ªè‹±æ–‡æ–‡ä»¶ä¸­ï¼Œéšåæ‰“å¼€ç³»ç»Ÿå±æ€§â¡ç¯å¢ƒå˜é‡â¡ç³»ç»Ÿå˜é‡â¡æ–°å»ºâ¡å˜é‡å`HADOOP_HOME`ï¼Œå˜é‡å€¼(binç›®å½•æ‰€åœ¨è·¯å¾„)â¡åœ¨`Path`é‡Œæ–°å»º`%HADOOP_HOME%\bin`â¡å›åˆ°`\bin`ï¼Œç‚¹å‡»winutils.exeï¼Œæœ‰çŸ­æš‚é—ªçƒå¯åŠ¨çª—å£å³å¯



## 5.2 æ–°å»ºspringbooté¡¹ç›®

### 5.2.1 pomæ–‡ä»¶

```xml
       <dependency>
            <groupId>org.apache.hadoop</groupId>
            <artifactId>hadoop-client</artifactId>
            <version>3.1.3</version>
        </dependency>

        <dependency>
            <groupId>org.slf4j</groupId>
            <artifactId>slf4j-log4j12</artifactId>
        </dependency>
```



### 5.2.2 logé…ç½®

åœ¨é¡¹ç›®çš„`src/main/resources`ç›®å½•ä¸‹åˆ›å»º`log4j.properties`æ–‡ä»¶ï¼ˆfileï¼‰ï¼Œåœ¨æ–‡ä»¶ä¸­å¡«å…¥

```properties
log4j.rootLogger=INFO, stdout
log4j.appender.stdout=org.apache.log4j.ConsoleAppender
log4j.appender.stdout.layout=org.apache.log4j.PatternLayout
log4j.appender.stdout.layout.ConversionPattern=%d %p [%c] - %m%n
log4j.appender.logfile=org.apache.log4j.FileAppender
log4j.appender.logfile.File=target/spring.log
log4j.appender.logfile.layout=org.apache.log4j.PatternLayout
log4j.appender.logfile.layout.ConversionPattern=%d %p [%c] - %m%n
```



### 5.2.3 è·å–å®¢æˆ·ç«¯

```java
    /**
     * å®¢æˆ·ç«¯ä»£ç å¸¸ç”¨å¥—è·¯ï¼š
     * 1. è·å–ä¸€ä¸ªå®¢æˆ·ç«¯å¯¹è±¡
     * 2. æ‰§è¡Œç›¸å…³çš„æ“ä½œå‘½ä»¤
     * 3. å…³é—­èµ„æº
     */ 
 Configuration configuration = new Configuration();
 //1.è¿æ¥é›†ç¾¤nnåœ°å€ 8020 æ˜¯hdfså†…éƒ¨é€šä¿¡é»˜è®¤ç«¯å£
 //2.é…ç½®
 //3.ç”¨æˆ·å:åœ¨core-site.xml ä¸­é…ç½®çš„ç”¨æˆ·å
 FileSystem fs = FileSystem.get(new URI("hdfs://192.168.79.102:8020"), configuration, "root");
 //åˆ›å»ºä¸€ä¸ªæ–‡ä»¶ç›®å½•
 fs.mkdirs(new Path("/javaHdfs"));
 //å…³é—­èµ„æº
 fs.close();
```



### 5.2.4 é…ç½®ä¼˜å…ˆçº§

å‚æ•°ä¼˜å…ˆçº§(ä½ => é«˜)ï¼š`hdfs-default.xml` => `hdfs-site.xml` => åœ¨é¡¹ç›®èµ„æºç›®å½•ä¸‹çš„é…ç½®æ–‡ä»¶ => ä»£ç é‡Œé¢çš„é…ç½® --> é«˜è¦†ç›–ä½

> æœ€é«˜ä¼˜å…ˆçº§ åœ¨Configurationä¸­è¿›è¡Œè®¾ç½®

```java
Configuration configuration = new Configuration();
//è®¾ç½®å‰¯æœ¬æ•°é‡ä¸º1
configuration.set("dfs.replication","1");
```

> ç¬¬äºŒä¼˜å…ˆçº§ åœ¨resoureç›®å½•ä¸‹çš„hdfs-site.xml

```xml
<?xml version="1.0"?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>

<configuration>

    <property>
        <name>dfs.replication</name>
        <value>1</value>
    </property>

</configuration>
```



### 5.2.5 ä¸Šä¼ æ–‡ä»¶

>å‚æ•°ä¸€æ˜¯å¦åˆ é™¤åŸæ•°æ®
>å‚æ•°äºŒè¡¨ç¤ºæ˜¯å¦å…è®¸è¦†ç›–
>å‚æ•°ä¸‰è¡¨ç¤ºåŸæ•°æ®è·¯å¾„ï¼ˆæœ¬åœ°ï¼‰
>å‚æ•°å››è¡¨ç¤ºç›®çš„åœ°è·¯å¾„

```java
fs.copyFromLocalFile(false,true,new Path("D:\\ç®€å†\\17723586644.pdf"),new Path("/javaHdfs/ç®€å†.pdf"));
```



### 5.2.6 è¿½åŠ 

```java
FSDataOutputStream fsDataOutputStream = fs.appendFile(new Path("/javaHdfs/111.txt")).build();
fsDataOutputStream.writeUTF("é˜¿æ£®çº³å‘Šè¯‰ä½ é«˜æ–¯é—¹æ­»é‚£ä¸ªå“¦iå•Šæ˜¯å“ªä¸ªioasniosangoisan");
fsDataOutputStream.close();
```



### 5.2.7 æ–‡ä»¶ä¸‹è½½

>å‚æ•°ä¸€æ˜¯å¦è¡¨ç¤ºåˆ é™¤åŸæ•°æ®
>å‚æ•°äºŒï¼šåŸæ–‡ä»¶è·¯å¾„HDFS
>å‚æ•°ä¸‰ï¼šç›®æ ‡åœ°å€è·¯å¾„windows
>å‚æ•°å››ï¼šæ˜¯å¦å¼€å¯æœ¬åœ°æ ¡éªŒï¼ˆé€šè¿‡`.crc`æ–‡ä»¶æ ¡éªŒï¼‰

```java
fs.copyToLocalFile(false,new Path("/javaHdfs/111.txt"),new Path("D:\\1\\111.txt"),false);
```



### 5.2.8 æ–‡ä»¶åˆ é™¤

```java
//åˆ é™¤æ–‡ä»¶
fs.delete(new Path("/javaHdfs/111.txt"), false);
//åˆ é™¤ç›®å½• true-æ˜¯å¦é€’å½’åˆ é™¤
fs.delete(new Path("/javaHdfs"), true);
```



### 5.2.9 æ–‡ä»¶æ›´åå’Œç§»åŠ¨

```java
//é‡å‘½å
fs.rename(new Path("/input/test.txt"),new Path("/input/test3.txt"));
//ç§»åŠ¨
fs.rename(new Path("/input/test2.txt"),new Path("/java/test2.txt"));
```



### 5.2.10 è·å–æ–‡ä»¶è¯¦æƒ…

```java
 RemoteIterator<LocatedFileStatus> files = fs.listFiles(new Path("/"), true);
 while (files.hasNext()) {
     LocatedFileStatus file = files.next();
     System.out.println("==========" + file.getPath() + "==========");
     System.out.println(file.getPermission());
     System.out.println(file.getOwner());
     System.out.println(file.getGroup());
     System.out.println(file.getLen());
     System.out.println(file.getAccessTime());
     System.out.println(file.getReplication());
     System.out.println(file.getBlockSize());
     System.out.println(file.getPath().getName());
     //è·å–å—ä¿¡æ¯
     BlockLocation[] blockLocations = file.getBlockLocations();
     System.out.println(Arrays.toString(blockLocations));
 }
```



### 5.2.11 æ–‡ä»¶å’Œæ–‡ä»¶å¤¹åˆ¤æ–­

```java
RemoteIterator<LocatedFileStatus> files = fs.listFiles(new Path("/"), true);
while (files.hasNext()) {
    LocatedFileStatus fileStatus = files.next();
    if
        (fileStatus.isFile()) System.out.println("æ–‡ä»¶ï¼š" + fileStatus.getPath().getName());
    else
        System.out.println("æ–‡ä»¶ç›®å½•ï¼š" + fileStatus.getPath().getName());
}
```



# å…­.HDFSçš„è¯»å†™æµç¨‹ â­

## 6.1 æ–‡ä»¶å†™å…¥

### 6.1.1 å†™å…¥æ•°æ®æµç¨‹å›¾

![image-20230927100716113](img.assets\image-20230927100716113.png)

>æµç¨‹è§£æï¼š
>
>- å®¢æˆ·ç«¯é€šè¿‡ Distributed FileSystem æ¨¡å—å‘ NameNode è¯·æ±‚ä¸Šä¼ æ–‡ä»¶ï¼ŒNameNode æ£€æŸ¥ç›®æ ‡æ–‡ä»¶æ˜¯å¦å·²å­˜åœ¨ï¼Œçˆ¶ç›®å½•æ˜¯å¦å­˜åœ¨
>
>- NameNode è¿”å›æ˜¯å¦å¯ä»¥ä¸Šä¼ 
>- å®¢æˆ·ç«¯è¯·æ±‚ç¬¬ä¸€ä¸ª Block ä¸Šä¼ åˆ°å“ªå‡ ä¸ª DataNode æœåŠ¡å™¨ä¸Š
>- NameNode è¿”å› 3 ä¸ª DataNode èŠ‚ç‚¹ï¼Œåˆ†åˆ«ä¸º dn1ã€dn2ã€dn3
>- å®¢æˆ·ç«¯é€šè¿‡ FSDataOutputStream æ¨¡å—è¯·æ±‚ dn1 ä¸Šä¼ æ•°æ®ï¼Œdn1 æ”¶åˆ°è¯·æ±‚ä¼šç»§ç»­è°ƒç”¨dn2ï¼Œç„¶å dn2 è°ƒç”¨ dn3ï¼Œå°†è¿™ä¸ªé€šä¿¡ç®¡é“å»ºç«‹å®Œæˆ
>  dn1ã€dn2ã€dn3 é€çº§åº”ç­”å®¢æˆ·ç«¯
>- å®¢æˆ·ç«¯å¼€å§‹å¾€ dn1 ä¸Šä¼ ç¬¬ä¸€ä¸ª Blockï¼ˆå…ˆä»ç£ç›˜è¯»å–æ•°æ®æ”¾åˆ°ä¸€ä¸ªæœ¬åœ°å†…å­˜ç¼“å­˜ï¼‰ï¼Œä»¥ Packet ä¸ºå•ä½ï¼Œdn1 æ”¶åˆ°ä¸€ä¸ª Packet å°±ä¼šä¼ ç»™ dn2ï¼Œdn2 ä¼ ç»™ dn3ï¼›dn1 æ¯ä¼ ä¸€ä¸ª packetä¼šæ”¾å…¥ä¸€ä¸ªåº”ç­”é˜Ÿåˆ—ç­‰å¾…åº”ç­”
>- å½“ä¸€ä¸ª Block ä¼ è¾“å®Œæˆä¹‹åï¼Œå®¢æˆ·ç«¯å†æ¬¡è¯·æ±‚ NameNode ä¸Šä¼ ç¬¬äºŒä¸ª Block çš„æœåŠ¡å™¨





### 6.1.2 ç½‘è·¯æ‹“æ‰‘â€“èŠ‚ç‚¹è·ç¦»è®¡ç®—

åœ¨HDFS å†™æ•°æ®çš„è¿‡ç¨‹ä¸­ï¼ŒNameNodeä¼šé€‰æ‹©**`è·ç¦»å¾…ä¸Šä¼ æ•°æ®æœ€è¿‘è·ç¦»`**çš„DataNodeæ¥æ”¶æ•°æ®ã€‚

> **èŠ‚ç‚¹è·ç¦»å³ä¸¤ä¸ªèŠ‚ç‚¹åˆ°è¾¾æœ€è¿‘çš„å…±åŒç¥–å…ˆçš„è·ç¦»ä¹‹å’Œ**

![image-20230927101700143](img.assets\image-20230927101700143.png)

> æ•°çº¿



### 6.1.3 æœºæ¶æ„ŸçŸ¥(å‰¯æœ¬å­˜å‚¨èŠ‚ç‚¹é€‰æ‹©)

[å®˜ç½‘è¯´æ˜](https://hadoop.apache.org/docs/r3.1.3/hadoop-project-dist/hadoop-hdfs/HdfsDesign.html#Data_Replication)

> For the common case, when the replication factor is three, HDFSâ€™s placement policy is to put `one replica on the local machine if the writer is on a datanode`, otherwise on a random datanode, `another replica on a node in a different (remote) rack`, and `the last on a different node in the same remote rack`.

åœ¨å¸¸è§æƒ…å†µä¸‹ï¼Œå½“HDFSçš„å¤åˆ¶å› å­ä¸ºä¸‰æ—¶ï¼ŒHDFSçš„æ•°æ®åˆ†å¸ƒç­–ç•¥æ˜¯è¿™æ ·çš„ï¼š

1. å¦‚æœå†™å…¥æ•°æ®çš„èŠ‚ç‚¹æ˜¯ä¸€ä¸ªæ•°æ®èŠ‚ç‚¹ï¼ˆdatanodeï¼‰ï¼Œåˆ™å°†ä¸€ä¸ªæ•°æ®å‰¯æœ¬æ”¾åœ¨æœ¬åœ°æœºå™¨ä¸Šã€‚å¦åˆ™ï¼Œå°†ä¸€ä¸ªæ•°æ®å‰¯æœ¬æ”¾åœ¨éšæœºé€‰æ‹©çš„ä¸€ä¸ªæ•°æ®èŠ‚ç‚¹ä¸Šã€‚
2. å°†å¦ä¸€ä¸ªæ•°æ®å‰¯æœ¬æ”¾åœ¨ä¸€ä¸ªä½äºä¸åŒï¼ˆè¿œç¨‹ï¼‰æœºæ¶çš„èŠ‚ç‚¹ä¸Šã€‚
3. æœ€åä¸€ä¸ªæ•°æ®å‰¯æœ¬æ”¾åœ¨åŒä¸€è¿œç¨‹æœºæ¶ä¸Šçš„å¦ä¸€ä¸ªä¸åŒèŠ‚ç‚¹ä¸Šã€‚

![image-20230927102616290](img.assets\image-20230927102616290.png)

> `BlockPlacementPolicyDefault`ï¼Œåœ¨è¯¥ç±»ä¸­ `chooseTargetInOrder` æ–¹æ³•å¯ä»¥æŸ¥çœ‹å‰¯æœ¬çš„é€‰æ‹©æºç 



## 6.2 æ–‡ä»¶è¯»å–

### 6.2.1 è¯»å–æ•°æ®æµç¨‹

> ä¸²è¡Œè¯»

![image-20230927103316673](img.assets\image-20230927103316673.png)

>æµç¨‹è§£æï¼š
>
>- å®¢æˆ·ç«¯é€šè¿‡ DistributedFileSystem å‘ NameNode è¯·æ±‚ä¸‹è½½æ–‡ä»¶ï¼ŒNameNode é€šè¿‡æŸ¥è¯¢å…ƒæ•°æ®ï¼Œæ‰¾åˆ°æ–‡ä»¶å—æ‰€åœ¨çš„ DataNode åœ°å€
>- æŒ‘é€‰ä¸€å° DataNodeï¼ˆå°±è¿‘åŸåˆ™ï¼Œç„¶åéšæœºï¼‰æœåŠ¡å™¨ï¼Œè¯·æ±‚è¯»å–æ•°æ®
>- DataNode å¼€å§‹ä¼ è¾“æ•°æ®ç»™å®¢æˆ·ç«¯ï¼ˆä»ç£ç›˜é‡Œé¢è¯»å–æ•°æ®è¾“å…¥æµï¼Œä»¥ Packet ä¸ºå•ä½æ¥åšæ ¡éªŒï¼‰
>- å®¢æˆ·ç«¯ä»¥ Packet ä¸ºå•ä½æ¥æ”¶ï¼Œå…ˆåœ¨æœ¬åœ°ç¼“å­˜ï¼Œç„¶åå†™å…¥ç›®æ ‡æ–‡ä»¶



# ä¸ƒ.NNå’Œ2NN

## 7.1 NNå’Œ2NNçš„å·¥ä½œæœºåˆ¶

NameNodeå…ƒæ•°æ®å­˜å‚¨ï¼š

`FsImageé•œåƒæ–‡ä»¶ï¼Œåœ¨ç£ç›˜ä¸­å¤‡ä»½å…ƒæ•°æ®`ï¼Œé‡‡ç”¨`ä¸æ›´æ–°ç”¨Editsè¿½åŠ `çš„æ–¹å¼ï¼Œä¸€æ—¦ NameNode èŠ‚ç‚¹æ–­ç”µï¼Œå¯ä»¥é€šè¿‡ `FsImage å’Œ Edits çš„åˆå¹¶`ï¼Œåˆæˆå…ƒæ•°æ®ã€‚

ä½†æ˜¯ï¼Œå¦‚æœé•¿æ—¶é—´æ·»åŠ æ•°æ®åˆ° Edits ä¸­ï¼Œä¼šå¯¼è‡´è¯¥æ–‡ä»¶æ•°æ®è¿‡å¤§ï¼Œæ•ˆç‡é™ä½ï¼Œè€Œä¸”ä¸€æ—¦æ–­ç”µï¼Œæ¢å¤å…ƒæ•°æ®éœ€è¦çš„æ—¶é—´è¿‡é•¿ã€‚

å› æ­¤ï¼Œéœ€è¦å®šæœŸè¿›è¡Œ FsImage å’Œ Edits çš„åˆå¹¶ï¼Œå¦‚æœè¿™ä¸ªæ“ä½œç”±NameNodeèŠ‚ç‚¹å®Œæˆï¼Œåˆä¼šæ•ˆç‡è¿‡ä½ã€‚å› æ­¤ï¼Œå¼•å…¥ä¸€ä¸ª`æ–°çš„èŠ‚ç‚¹SecondaryNamenode`ï¼Œä¸“é—¨ç”¨äº FsImage å’Œ Edits çš„åˆå¹¶

![image-20230927104706824](img.assets\image-20230927104706824.png)

> ç¬¬ä¸€é˜¶æ®µï¼šNameNode å¯åŠ¨

1. ç¬¬ä¸€æ¬¡å¯åŠ¨ NameNode æ ¼å¼åŒ–åï¼Œåˆ›å»º Fsimage å’Œ Edits æ–‡ä»¶ã€‚å¦‚æœä¸æ˜¯ç¬¬ä¸€æ¬¡å¯åŠ¨ï¼Œç›´æ¥åŠ è½½ç¼–è¾‘æ—¥å¿—å’Œé•œåƒæ–‡ä»¶åˆ°å†…å­˜
2. å®¢æˆ·ç«¯å¯¹å…ƒæ•°æ®è¿›è¡Œå¢åˆ æ”¹çš„è¯·æ±‚
3. NameNode è®°å½•æ“ä½œæ—¥å¿—ï¼Œæ›´æ–°æ»šåŠ¨æ—¥å¿—
4. NameNode åœ¨å†…å­˜ä¸­å¯¹å…ƒæ•°æ®è¿›è¡Œå¢åˆ æ”¹

> ç¬¬äºŒé˜¶æ®µï¼šSecondary NameNode å·¥ä½œ

5. Secondary NameNode è¯¢é—® NameNode æ˜¯å¦éœ€è¦ CheckPointã€‚ç›´æ¥å¸¦å› NameNodeæ˜¯å¦æ£€æŸ¥ç»“æœ
6. Secondary NameNode è¯·æ±‚æ‰§è¡Œ CheckPointã€‚
7. NameNode æ»šåŠ¨æ­£åœ¨å†™çš„ Edits æ—¥å¿—ã€‚å°†æ»šåŠ¨å‰çš„ç¼–è¾‘æ—¥å¿—å’Œé•œåƒæ–‡ä»¶æ‹·è´åˆ° Secondary NameNode
8. Secondary NameNode åŠ è½½ç¼–è¾‘æ—¥å¿—å’Œé•œåƒæ–‡ä»¶åˆ°å†…å­˜ï¼Œå¹¶åˆå¹¶ã€‚ç”Ÿæˆæ–°çš„é•œåƒæ–‡ä»¶ fsimage.chkpoint
9. æ‹·è´ fsimage.chkpoint åˆ° NameNodeã€‚NameNode å°† fsimage.chkpoint é‡æ–°å‘½åæˆ fsimage



## 7.2 FsImageå’ŒEdits

> åœ¨nameNodeèŠ‚ç‚¹ä¸­çš„FsImageå’ŒEdits
>
> /opt/module/hadoop-3.1.3/data/dfs/name/current

![image-20230927105447439](img.assets\image-20230927105447439.png)

>åœ¨Secondary nameNodeèŠ‚ç‚¹ä¸­çš„FsImageå’ŒEdits
>
>/opt/module/hadoop-3.1.3/data/dfs/namesecondary/current

![image-20230927105530683](img.assets\image-20230927105530683.png)


Fsimageæ–‡ä»¶ï¼šæ˜¯HDFSæ–‡ä»¶ç³»ç»Ÿå…ƒæ•°æ®çš„ä¸€ä¸ª`æ°¸ä¹…æ€§çš„æ£€æŸ¥ç‚¹`ï¼Œå…¶ä¸­åŒ…å«HDFSæ–‡ä»¶ç³»ç»Ÿçš„æ‰€æœ‰ç›®å½•å’Œæ–‡ä»¶inodeçš„åºåˆ—åŒ–ä¿¡æ¯

Editsæ–‡ä»¶ï¼šå­˜æ”¾HDFSæ–‡ä»¶ç³»ç»Ÿçš„æ‰€æœ‰æ›´æ–°æ“ä½œçš„è·¯å¾„ï¼ˆ`ä¸€åˆ‡è¿½åŠ æ“ä½œ`ï¼‰ï¼Œæ–‡ä»¶ç³»ç»Ÿå®¢æˆ·ç«¯æ‰§è¡Œçš„æ‰€æœ‰å†™æ“ä½œé¦–å…ˆä¼šè¢«è®°å½•åˆ°Editsæ–‡ä»¶ä¸­

seen_txidæ–‡ä»¶ï¼šä¿å­˜çš„æ˜¯ä¸€ä¸ªæ•°å­—ï¼Œå°±æ˜¯æœ€åä¸€ä¸ªedits_çš„æ•°å­—

>æ¯æ¬¡NameNodeå¯åŠ¨çš„æ—¶å€™éƒ½ä¼šå°†Fsimageæ–‡ä»¶è¯»å…¥å†…å­˜ï¼ŒåŠ è½½Editsé‡Œé¢çš„æ›´æ–°æ“ä½œï¼Œä¿è¯å†…å­˜ä¸­çš„å…ƒæ•°æ®ä¿¡æ¯æ˜¯æœ€æ–°çš„ã€åŒæ­¥çš„ï¼Œå¯ä»¥çœ‹æˆNameNodeå¯åŠ¨çš„æ—¶å€™å°±å°†Fsimageå’ŒEditsæ–‡ä»¶è¿›è¡Œäº†åˆå¹¶



### 7.2.1 oivæŸ¥çœ‹FsImageæ–‡ä»¶

```shell
hdfs oiv -p æ–‡ä»¶ç±»å‹ -i é•œåƒæ–‡ä»¶ -o è½¬æ¢åæ–‡ä»¶è¾“å‡ºè·¯å¾„
```

```shell
# æŸ¥çœ‹fsimage_0000000000000000025çš„å†…å®¹
hdfs oiv -p XML -i fsimage_0000000000000000025 -o /opt/module/hadoop/fsimage.xml
cat /opt/module/hadoop/fsimage.xml
```

> å­˜å‚¨æœ‰NNçš„é•œåƒæ•°æ®ï¼Œæ–‡ä»¶ä¿¡æ¯ç­‰ï¼Œä½†æ˜¯æ²¡æœ‰æ–‡ä»¶å—ä¿¡æ¯ï¼ˆå…¶ä»–æœåŠ¡å™¨ä¸Šï¼‰ï¼Œå…¶ä»–æœåŠ¡å™¨DateNodeä¼šè·ŸNNæŠ¥å‘Šæ–‡ä»¶å—



### 7.2.2 oevæŸ¥çœ‹Editsæ–‡ä»¶

```shell
hdfs oev -p æ–‡ä»¶ç±»å‹ -i ç¼–è¾‘æ—¥å¿— -o è½¬æ¢åæ–‡ä»¶è¾“å‡ºè·¯å¾„
```

```shell
hdfs oev -p XML -i edits_0000000000000000012-0000000000000000013 -o /opt/module/hadoop/edits.xml
```



### 7.2.3 CheckPointæ—¶é—´è®¾ç½®

> åœ¨`hdfs-default.xml`é»˜è®¤é…ç½®æ–‡ä»¶ä¸­ï¼Œè®¾ç½®äº†æ£€æŸ¥æ—¶é—´

1. é€šå¸¸æƒ…å†µä¸‹ï¼ŒSecondaryNameNode æ¯éš”`ä¸€å°æ—¶`æ‰§è¡Œä¸€æ¬¡ã€‚

```xml
<property>
 <name>dfs.namenode.checkpoint.period</name>
 <value>3600s</value>
</property>
```

2. `ä¸€åˆ†é’Ÿ`æ£€æŸ¥ä¸€æ¬¡æ“ä½œæ¬¡æ•°ï¼Œå½“æ“ä½œæ¬¡æ•°è¾¾åˆ° `1 ç™¾ä¸‡`æ—¶ï¼ŒSecondaryNameNode æ‰§è¡Œä¸€æ¬¡ã€‚

```xml
<property>
	<name>dfs.namenode.checkpoint.txns</name>
 	<value>1000000</value>
	<description>æ“ä½œåŠ¨ä½œæ¬¡æ•°</description>
</property>

<property>
 	<name>dfs.namenode.checkpoint.check.period</name>
 	<value>60s</value>
	<description> 1 åˆ†é’Ÿæ£€æŸ¥ä¸€æ¬¡æ“ä½œæ¬¡æ•°</description>
</property>
```



# å…«.DateNode

## 8.1 DateNodeå·¥ä½œæœºåˆ¶

![image-20230927120144595](img.assets\image-20230927120144595.png)

>**æµç¨‹è§£æ**ï¼š
>
>1. DataNodeå¯åŠ¨åå‘NameNodeæ³¨å†Œ
>2. æ³¨å†ŒæˆåŠŸåå‘DataNodeè¿”å›ä¿¡å·
>3. DNå¼€å§‹æ¯å‘¨æœŸï¼ˆ6å°æ—¶ï¼‰ä¸ŠæŠ¥æ‰€æœ‰å—ä¿¡æ¯
>4. å¿ƒè·³æ¯3ç§’ä¸€æ¬¡ï¼ˆä¸¤è€…é€šè®¯ï¼‰ï¼Œå¿ƒè·³è¿”å›ç»“æœå¸¦æœ‰NameNodeç»™DataNodeçš„å‘½ä»¤
>5. è¶…è¿‡10åˆ†é’Ÿ+30ç§’æ²¡æœ‰æ”¶åˆ°DNçš„å¿ƒè·³ï¼ŒNNåˆ™è®¤ä¸ºè¯¥èŠ‚ç‚¹ä¸å¯ç”¨

> åœ¨`hdfs-default.xml`é»˜è®¤é…ç½®æ–‡ä»¶ï¼ŒDN å‘ NN æ±‡æŠ¥å½“å‰è§£è¯»ä¿¡æ¯çš„æ—¶é—´é—´éš”ï¼Œé»˜è®¤ 6 å°æ—¶

```xml
<property>
	<name>dfs.blockreport.intervalMsec</name>
	<value>21600000</value>
	<description>Determines block reporting interval in milliseconds.</description>
</property>
```

> DN æ‰«æè‡ªå·±èŠ‚ç‚¹å—ä¿¡æ¯åˆ—è¡¨çš„æ—¶é—´ï¼Œé»˜è®¤ 6 å°æ—¶

```xml
<property>
	<name>dfs.datanode.directoryscan.interval</name>
	<value>21600s</value>
</property>
```



## 8.2 æ•°æ®å®Œæ•´æ€§

DataNode èŠ‚ç‚¹ä¿è¯æ•°æ®å®Œæ•´æ€§çš„æ–¹æ³•

1. å½“ DataNode è¯»å– Block çš„æ—¶å€™ï¼Œå®ƒä¼šè®¡ç®— CheckSum
2. å¦‚æœè®¡ç®—åçš„ CheckSumï¼Œä¸ Block åˆ›å»ºæ—¶å€¼ä¸ä¸€æ ·ï¼Œè¯´æ˜ Block å·²ç»æŸå
3. Client è¯»å–å…¶ä»– DataNode ä¸Šçš„ Block
4. å¸¸è§çš„æ ¡éªŒç®—æ³• `crcï¼ˆ32ï¼‰`ï¼Œmd5ï¼ˆ128ï¼‰ï¼Œsha1ï¼ˆ160ï¼‰
5. DataNode åœ¨å…¶æ–‡ä»¶åˆ›å»ºåå‘¨æœŸéªŒè¯ CheckSum

![image-20230927121847537](img.assets\image-20230927121847537.png)



## 8.3 æ‰çº¿æ—¶é™å‚æ•°è®¾ç½®

![image-20230927122021766](img.assets\image-20230927122021766.png)

>éœ€è¦æ³¨æ„çš„æ˜¯ hdfs-site.xml é…ç½®æ–‡ä»¶ä¸­çš„ `heartbeat.recheck.interval` çš„å•ä½ä¸º`æ¯«ç§’`ï¼Œ `dfs.heartbeat.interval` çš„å•ä½ä¸º`ç§’`ã€‚

```xml
<property>
 	<name>dfs.namenode.heartbeat.recheck-interval</name>
 	<value>300000</value>
</property>

<property>
 	<name>dfs.heartbeat.interval</name>
 	<value>3</value>
</property>
```

